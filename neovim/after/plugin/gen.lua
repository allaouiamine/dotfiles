require('gen').setup({
    opts = {
        model = "llama3", -- The default model to use.
        host = "ollama", -- The host running the Ollama service.
        show_model = true, -- Displays which model you are using at the beginning of your chat session.
        show_prompt = true
    },
    --prompts=
})




